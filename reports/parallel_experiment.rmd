---
title: "Parallelisation Experiment"
date: "`r Sys.Date()`"
params:
  HwInfo: (Hardware Info)
  OsInfo: (OS Info)
  Machine: (Machine Info)
  GoInfo: (GO Info)
  GitHash: (GithubKey)
  StateDB: (StateDB)
  VM: (VM)
  db: ./test.db
---

```{r, include = FALSE}
library(ggplot2)
library(dplyr)
library(RSQLite)
con <- dbConnect(SQLite(), params$db)
data <- dbReadTable(con, 'blockProfile')

# Find parallelisable blocks whose speedup is greater than 1.0
parallelisable <- data %>% filter(speedup > 1.0)

# Compress data to 100K blocks for visualisation
group_size <- 100000
data$block_group <- data$block %/% group_size
reducedData <- data %>% group_by(block_group)  %>% summarise(speedup=exp(mean(log(speedup))))
reducedData$block <- reducedData$block_group * group_size

# close DB
dbDisconnect(con)
```

## 1. Experiment
The experiment is run on the machine `r params$Machine`, which is a `r params$HwInfo` computer.
The operating system is `r params$OsInfo`.
The system has installed `r params$GoInfo`.
The github hash of the Aida repository is `r params$GitHash`.
For this experiment, we use **`r params$StateDB`** as a StateDB and **`r params$VM`** as a virtual machine.
The data set for this experiment is stored in the database `r params$db`.

The experiment was conducted for the block range from **`r format(min(data$block),big.mark=",")`**  to **`r format(max(data$block),big.mark=",")`**.

## 2. Degree of Parallelisation

The parallelisation experiment simulates the parallel execution of transactions inside a block.
We assume the best possible/theoretical scheduling called clairvoyance scheduling.
The background about this parallel experiment is summarised in this [slide stack](https://docs.google.com/presentation/d/1us5ViXOMftJqktXY3Yf8MGTzed6NKaiq/edit?usp=sharing&ouid=115076270420310973960&rtpof=true&sd=true).
The schedule is constructed with the [substate work](https://usenix.org/conference/atc21/presentation/kim-yeonsoo).
Two transactions inside a block interfere if they use the same contract addresses.
Note that this information is available after the execution of a smart contract only.
A concrete implementation requires a prediction/speculative execution mechanism requiring extra overheads, drastically diminishing the presented speedup values.
In this experiment, the overheads of a prediction/speculative execution mechanism are not considered.
Hence, the presented numbers are best-case scenarios and are not realisable in a concrete implementation.

We have `r format(nrow(data), big.mark=",")` blocks, of which `r format(nrow(parallelisable), big.mark=",")` are parallelisable.
The number of strictly sequential blocks (not parallelisable) is `r format(100.0*(nrow(data)-nrow(parallelisable))/nrow(data), digits=4)`%.
The maximal achievable parallelism in a block is `r format(max(data$speedup), digits=4)`.
The geometric mean of the speedup is **`r format(exp(mean(log(data$speedup))), digits=4)`**.

We show the distribution of the speedup for blocks that are not sequential.
Sequential blocks whose speedup is one are omitted from the following distribution:

```{r, echo = FALSE, message=FALSE}
hist(parallelisable$speedup, main="Speedup Distribution without Sequential Blocks", breaks = quantile(parallelisable$speedup, 0:10 / 10), xlab="Speedup", col="lightblue1")
lines(density(parallelisable$speedup), col="dodgerblue3", lwd=2)
```

The following figure shows the speedup over block height. Points are the geometric mean of 100K aggregated blocks,
for which we did not filter the sequential blocks.

```{r, echo = FALSE, message=FALSE}
reducedData %>%
  ggplot(aes(x = block, y = speedup)) +
  geom_smooth(color = "tomato") +
  geom_point(alpha=0.3) +
  labs(x="Block Height", y="Speedup")
```

## 3. Processor Utilisation / Efficiency

We measure the processor utilisation of a block by constructing the task graph for a block.
The width of the task graph is a proxy for the maximum number of processors that may be required to achieve the speedup.
The ratio between speedup and width gives an upper bound on the processor utilisation (aka. efficiency).
However, a precise measure of efficiency is NP-hard problem and cannot be computed in polynomial time.

The average number of processors is `r mean(data$ubNumProc)` to execute the task graphs optimally with a maximum of `r max(data$ubNumProc)`.
The lower bound of the processor utilisation is `r format(100.0*exp(mean(log(data$speedup/data$ubNumProc))), digits=4)`% on average, with a maximum of `r max(data$ubNumProc)` processors (upper bound).  A processor utilisation histogram for only parallelisable blocks (i.e. blocks whose speed-up is greater than one) is shown below,

```{r, echo = FALSE, message=FALSE}
parallelisable$utilisation <- parallelisable$speedup / parallelisable$ubNumProc
hist(parallelisable$utilisation, main="Processor Utilisation/Effienciy for Best Speedup", breaks = quantile(parallelisable$utilisation, 0:10 / 10), xlab="Processor Utilisation", col="lightblue1")
lines(density(parallelisable$utilisation), col="dodgerblue3", lwd=2)
```

## 4. Linear Prediction Model

```{r, message=FALSE, echo=FALSE}
data$tSequentialUSec <- data$tSequential / 1e3
data$tCriticalUSec <- data$tCritical / 1e3
lmSequentialTx <- lm(tSequentialUSec~numTx, data=data)
lmCriticalTx <- lm(tCriticalUSec~numTx, data=data)
coeffCriticalTx <- lmCriticalTx$coefficients
coeffSequentialTx <- lmSequentialTx$coefficients
a1 <- unname(coeffSequentialTx["numTx"])
b1 <- unname(coeffCriticalTx["numTx"])
a0 <- unname(coeffSequentialTx["(Intercept)"])
b0 <- unname(coeffCriticalTx["(Intercept)"])
tCommit <- mean(data$tCommit)
speedup <-  exp(mean(log(data$speedup)))
tn <- function (s) {
    (a0 - s * b0 + (1-s) * tCommit)/ (s * b1 - a1)
}
```

The linear speedup prediction model estimates a maximum theoretical speedup of `r format(a1/b1, digits=4)` assuming an infinite number
of processors. The underlying assumption of the prediction model is that the degree of parallisation (ratio of sequential
transaction execution time and critical path) does not change with an increasing number of transactions in a block. We have
functions for $t_{\textit{sequential}}(n)=$ `r a1` $n +$ `r a0` and $t_{\textit{criticial}}(n)=$ `r b1` $n +$ `r b0`
where $n$ is the number of transactions. The units of the functions are in microseconds.

The figure below shows the number of transactions required for achieving a given speedup between the speedup from the clairvoyance experiment and the five percent from the maximum theoretical speedup.

```{r, echo=FALSE, message=TRUE}
# check that fitting parameters are positive for plotting
if (a1 >= 0 && a0 >= 0 && b1 >= 0 && b0 >= 0) {
   # check that speedup range is positive
   if (speedup <= a1/b1) {
       X <- seq(speedup, speedup+(a1/b1-speedup)*0.95, 0.01)
       Y <- tn(X)
       plot(X,Y, type="l", lwd=2, col="tomato", main="Linear Prediction Model", xlab="Speedup", ylab="# Tx")
   } else {
    print("plotting not possible because of invalid speedup range")
   }
} else {
    print("plotting not possible because of negative coefficients of t_critical and/or t_sequential")
}
```

Note that the number of transactions grows infinitely reaching the maximum speedup of `r format(a1/b1, digits=4)`.
